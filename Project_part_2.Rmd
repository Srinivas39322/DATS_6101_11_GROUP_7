---
title: "Predicting app costs in Apple App store"
author: "Krishnasurya Gopalakrishnan, Monica Muniraj, Shashank Shivakumar, Srinivas Saiteja Tenneti"
date: "`r Sys.Date()`"
output: 
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = F, message = F)
options(scientific=T, digits = 3)

library(ezids)
library(tidyr)
library(lubridate)
library(dplyr)
library(ggplot2)
library(caret)
library(pROC)
library(randomForest)
library(dplyr)
library(corrplot)
```

## Introduction

<p>
In the dynamic world of mobile applications, a pressing question resonates among developers and investors: where should they channel their resources, and what elements truly dictate an app's success? As 2021 came to a close, the App Store, with its impressive roster of 1.6 million iOS applications, stood out as a hub of innovation and potential, even in comparison to Google's expansive Play Store with its 3.5 million apps.

This report embarks on an analytical journey into the second-largest app marketplace worldwide -- Apple's App Store. Here, we aim to unravel the myriad factors that determine an app's trajectory, from its pricing and size to user ratings and categories. These aren't just statistics; they form the foundation of strategic decision-making.

Our primary goal is straightforward: discern the pivotal variables that substantially impact an app's market success and profitability. For stakeholders, understanding these nuances is essential, providing a compass in the intensely competitive landscape of app development and marketing. This exploration aims to convert data into actionable insights, offering a roadmap to success.

Join us in this analytical expedition, where data narratives guide our way, and each insight serves as a beacon for informed strategic choices. Step into a world where in-depth research becomes the linchpin to harnessing the vast potential of the mobile application universe.
</p>

## Project 1 analysis:
<p>
Based on the findings from Project Phase 1, it is evident that the mobile app market is predominantly influenced by several key factors. The gaming genre emerges as a market leader, demonstrating its wide appeal and high user engagement. Significantly, apps rated for ages 4 and above dominate the market, accounting for around 80% of all apps, which indicates a strong demand for family-friendly content. Furthermore, free apps constitute 90% of the market, a trend likely driven by alternative revenue models like in-app purchases and advertisements. Weather apps notably stand out for receiving the most user ratings, reflecting their high user interaction, while developer-oriented apps have a narrower user base, as seen in their fewer ratings. Additionally, the majority of apps are designed to be compact, typically under 25MB, catering to ease of download and efficient storage management. These insights collectively shape our understanding of the current mobile app landscape, highlighting the significance of gaming and children-friendly apps, user preferences for free and compact apps, and the high engagement with certain app categories like weather apps. 
</p>

## SMART Question: 
<p>
Forecasting the likelihood of new apps being offered for free or as paid versions.
</p>

## Descriptive statistics
```{r}
df = read.csv('appleAppData.csv')
df <- na.omit(df)

df$Released_Year <- year(df$Released)
df$Updated_Year <- year(df$Updated)

df$Primary_Genre <- as.factor(df$Primary_Genre)
df$Content_Rating <- as.factor(df$Content_Rating)
df$DeveloperId <- as.factor(df$DeveloperId)
df$Released_Year <- as.factor(df$Released_Year)
df$Updated_Year <- as.factor(df$Updated_Year)

df$Size_MB <- df$Size_Bytes / (1024^2)
df$Size_Group <- cut(df$Size_MB,
                     breaks = seq(0, max(df$Size_MB), by = 50),
                     labels = seq(25, max(df$Size_MB) - 25, by = 50))

df$Primary_genre <- as.numeric(factor(df$Primary_Genre))
df$Content_rating <- as.numeric(factor(df$Content_Rating))
df$Free_Paid <- as.numeric(factor(df$Free))
df$Developer_ID <- as.numeric(df$DeveloperId)
df$Released_year <- as.numeric(df$Released_Year)
df$Updated_year <- as.numeric(df$Updated_Year)

print(str(df))
```
## Evaluating Feature Importance in App Pricing Prediction Using Random Forest

```{r}
features <- c("Primary_Genre", "Content_Rating", "Size_MB", "Average_User_Rating", "Reviews", "Released_Year", "Updated_Year")
target <- "Free"

rf_model <- randomForest(as.factor(Free) ~ ., data = df[, c(features, target)], ntree = 100)
importance <- importance(rf_model)
print(importance)
```
<p>
The importance of each feature is measured by the Mean Decrease in Gini coefficient, which indicates how much each feature contributes to the homogeneity of the nodes and leaves in the model. 

- **Primary_Genre (23069)**: This feature has the highest importance score, suggesting that the genre of an app is a critical factor in determining its pricing model. Apps in certain genres are more likely to be free or paid, influencing the model's decision significantly.

- **Size_MB (26683)**: The size of the app, measured in megabytes, is also a highly influential factor. This could indicate that larger apps (which might require more resources to develop) are more likely to be paid, or conversely, smaller apps tend to be free.

- **Average_User_Rating (10302)**: This feature has a considerable impact on the model's predictions. It implies that the average user rating of an app influences its likelihood of being free or paid, possibly reflecting user expectations and satisfaction levels.

- **Reviews (9688)**: The number of reviews an app receives is also an important factor. This could be due to the fact that more popular or widely used apps (which could correlate with a higher number of reviews) tend to have specific pricing strategies.

- **Released_Year (11493) and Updated_Year (7814)**: The years when the app was released and last updated are moderately important. This might reflect market trends and changes in app pricing strategies over time.

- **Content_Rating (2244)**: While still relevant, the content rating has the lowest importance score among the features. This suggests that while the intended audience age does play a role in pricing, it is less decisive compared to other factors like genre or size.

In summary, the Random Forest model highlights the diverse factors that contribute to the pricing model of an app, with the genre and size being the most significant. These insights can guide app developers and marketers in understanding what aspects might influence an app's likelihood of being free or paid.
</p>

## Selected Features for analysis
```{r}
selected_columns <- c("Primary_Genre", "Size_MB", "Average_User_Rating", "Released_Year", "Free")

df <- df[selected_columns]
df$Free <- as.factor(df$Free)
levels(df$Free) <- c(0, 1)

# na_counts <- colSums(is.na(df))
# print(na_counts)
str(df)
```

## Logistic Regression
### Methodology: Choosing Logistic Regression for Predicting App Pricing Models

<p>
In our analysis to predict whether mobile apps will be free or paid, we have chosen Logistic Regression as our primary statistical method. This decision is grounded in the nature of our target variable, which is binomial, presenting two distinct categories: free or paid. Logistic Regression is particularly adept at handling such binary outcomes. It operates by estimating the probability of an event occurrence, in this case, the likelihood of an app being free, based on various predictor variables such as app genre, target age group, and prevailing market trends. Its ability to provide probabilities and classify outcomes into distinct categories makes it an ideal choice for our predictive model. Furthermore, Logistic Regression is robust, relatively easy to implement, and interpret, which aids in the clear presentation and understanding of our results. These qualities collectively make Logistic Regression a fitting and reliable choice for our analysis in forecasting the pricing model of upcoming mobile apps.
</p>

```{r}
logistic_model_2 <- glm(Free ~ .,data = df, family = binomial)
# summary(logistic_model_2)
```

## Confusion Matrix for Logistic Regression
```{r}
predictions_2 <- factor(ifelse(predict(logistic_model_2, type = "response") > 0.5, 1, 0), levels = levels(df$Free))
actual_values_2 <- factor(df$Free, levels = levels(df$Free))

conf_matrix_2 <- confusionMatrix(predictions_2, actual_values_2)
print(conf_matrix_2)
```
<p>
From the above model metrics we can see that, although the model's accuracy is over 90% and the specificity being over 99%
</p>
## Distribution of Target variable
```{r}
free_apps <- df[df$Free == 1, ]
paid_apps <- df[df$Free == 0, ]

print(nrow(free_apps))
print(nrow(paid_apps))
```

<p>
From the above result we can see that there is a huge disparity between the two levels in the target variable. Almost a 11:1 ratio. Models trained on this data will result in bias in their predictions. 
</p>

```{r}
free_apps_sample <- free_apps %>% sample_n(102502)
print(nrow(free_apps_sample))
```

```{r}
merged_df <- rbind(free_apps_sample, paid_apps)
str(merged_df)
```

```{r}
print(head(merged_df))
merged_df <- merged_df[sample(1:205004), ]
print(head(merged_df))
```

```{r}
merged_df_free_apps <- df[df$Free == 1, ]
merged_df_paid_apps <- df[df$Free == 0, ]

print(nrow(merged_df_free_apps))
print(nrow(merged_df_paid_apps))
```
```{r}
logistic_model <- glm(Free ~ ., data = merged_df, family = binomial)
summary(logistic_model)
```

```{r}
predictions <- factor(ifelse(predict(logistic_model, type = "response") > 0.5, 1, 0), levels = levels(merged_df$Free))
actual_values <- factor(merged_df$Free, levels = levels(merged_df$Free))

conf_matrix <- confusionMatrix(predictions, actual_values)
print(conf_matrix)
```
# Random Forest

```{r}
selected_columns_3 <- c("Size_MB", "Average_User_Rating", "Released_Year", "Free")
dff <- df[selected_columns_3]
colnames(dff)
nrow(dff)
```

```{r}
# Assuming df is your data frame with the dependent variable 'Free' and other predictor variables

# Install and load the randomForest package if not already installed
# install.packages("randomForest")
library(randomForest)

# Set a seed for reproducibility
set.seed(123)

library(doParallel)
cl <- makeCluster(detectCores())
registerDoParallel(cl)

rf_model <- randomForest(Free ~ ., data = merged_df, ntree = 500, mtry = sqrt(ncol(merged_df) - 1), ncores = detectCores())

```

```{r}
summary(rf_model)
```

```{r}
# Assuming 'your_test_data' is your testing dataset
# predictions_rf <- factor(ifelse(predict(rf_model, newdata = merged_df, type = "response") > 0.5, 1, 0), levels = levels(merged_df$Free))
predictions_rf <- predict(rf_model, newdata = merged_df, type = "response")
results_rf <- data.frame(Actual = merged_df$Free, Predicted = predictions_rf)
library(caret)

# Create a confusion matrix
confusion_matrix_rf <- confusionMatrix(table(results_rf$Predicted, results_rf$Actual))
print(confusion_matrix_rf)
```
## Conclusion

<p>

1. **Recognizing the Impact of Skewed Data**: In real-world data analysis, skewness in data is a common occurrence. This skewness, if not addressed, can lead to the development of predictive models that fail to accurately capture the underlying patterns and trends. Recognizing and addressing this skewness is therefore essential in ensuring the validity of our models.

2. **Evaluating Model Performance on Different Data Sets**: Models trained on unbalanced data may exhibit high accuracy, but this metric can be deceptive. Such models might only be proficient in predicting the outcome for the over-represented class while neglecting the under-represented one. Conversely, models trained on balanced data, while potentially showing a slight decrease in overall accuracy, offer a more honest representation of their predictive capabilities across all classes.

3. **The Crucial Role of Data Balancing in Modeling**: The practice of balancing data, whether through resampling techniques or other methods, is not just a one-time adjustment but a repeated necessity throughout the model training process. By continually addressing the skewness in data, we enhance the model's reliability and accuracy, making it a more robust tool for predictions.

4. **Prioritizing Reliability Over Raw Accuracy**: A model that has been trained on balanced data may show a lower accuracy rate compared to its unbalanced counterpart. However, such a model is generally more reliable and offers a true reflection of its performance. This approach emphasizes the importance of a model's ability to predict outcomes accurately across all categories, rather than achieving a high accuracy rate on a skewed dataset.

5. **The Iterative Nature of Model Improvement**: The process of data balancing and model retraining is iterative, emphasizing the importance of continuous refinement. Each iteration aims to improve the model's ability to make accurate and dependable predictions. This ongoing process reflects the dynamic nature of data science and the constant need for adaptation to achieve the most accurate and reliable results.

In conclusion, these insights underscore the importance of understanding and addressing data skewness in predictive modeling. By prioritizing balanced data and reliability over raw accuracy, and committing to an iterative process of improvement, we can develop more effective and trustworthy predictive models.

</p>
